{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea073af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "378f7ad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=128, ckpt_dir='output/retrieval/vit_lr0.0001_0.0001_bs128_epoch30_arcface_m0.15_s30_translate_cn/', data='./dataset/dataset_v2', load_epoch=30, log_steps=1, lr=0.0003, m=0.15, max_epochs=10, num_class=181, query_list='./dataset/dataset_v2/query.txt', s=30.0, softmax=0, train_list='./dataset/dataset_v2/sample.txt', weight_decay=0.0001)\n"
     ]
    }
   ],
   "source": [
    "# set up args\n",
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "# for dataset\n",
    "parser.add_argument('--data', default='./dataset/dataset_v2')\n",
    "parser.add_argument('--train_list', default='./dataset/dataset_v2/sample.txt')\n",
    "parser.add_argument('--query_list', default='./dataset/dataset_v2/query.txt')\n",
    "# for model\n",
    "parser.add_argument('--num_class', default=181)\n",
    "parser.add_argument('--softmax', default=0, type=int)\n",
    "parser.add_argument('--s', default=30.0, type=float)\n",
    "parser.add_argument('--m', default=0.15, type=float)\n",
    "# for training\n",
    "parser.add_argument('--max_epochs', default=10)\n",
    "parser.add_argument('--batch_size', default=128)\n",
    "parser.add_argument('--lr', default=3e-4)\n",
    "parser.add_argument('--weight_decay', default=1e-4)\n",
    "# for visualization\n",
    "parser.add_argument('--log_steps', default=1)\n",
    "parser.add_argument('--ckpt_dir', default=\"output/retrieval/vit_lr0.0001_0.0001_bs128_epoch30_arcface_m0.15_s30_translate_cn/\")\n",
    "parser.add_argument('--load_epoch', default=30)\n",
    "\n",
    "args = parser.parse_args(args=[])\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "303d4b30",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerModel(\n",
       "  (backbone): VisionTransformer(\n",
       "    (conv_proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "    (encoder): Encoder(\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "      (layers): Sequential(\n",
       "        (encoder_layer_0): EncoderBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (self_attention): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): MLPBlock(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (encoder_layer_1): EncoderBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (self_attention): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): MLPBlock(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (encoder_layer_2): EncoderBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (self_attention): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): MLPBlock(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (encoder_layer_3): EncoderBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (self_attention): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): MLPBlock(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (encoder_layer_4): EncoderBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (self_attention): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): MLPBlock(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (encoder_layer_5): EncoderBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (self_attention): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): MLPBlock(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (encoder_layer_6): EncoderBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (self_attention): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): MLPBlock(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (encoder_layer_7): EncoderBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (self_attention): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): MLPBlock(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (encoder_layer_8): EncoderBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (self_attention): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): MLPBlock(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (encoder_layer_9): EncoderBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (self_attention): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): MLPBlock(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (encoder_layer_10): EncoderBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (self_attention): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): MLPBlock(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (encoder_layer_11): EncoderBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (self_attention): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): MLPBlock(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (ln): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "    )\n",
       "    (heads): Linear(in_features=768, out_features=2048, bias=True)\n",
       "  )\n",
       "  (arcface_cls): ArcMarginProduct()\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set up model\n",
    "from supervised.model import Model, DOLG, TransformerModel\n",
    "\n",
    "model = TransformerModel(num_class=args.num_class, args=args).cuda()\n",
    "model.load_state_dict(torch.load(os.path.join(args.ckpt_dir, \"model_{:0>2d}.ckpt\".format(args.load_epoch - 1))))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94840460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from supervised.dataset import Dataset\n",
    "\n",
    "query_dataset = Dataset(args.data, args.query_list, mode=\"test\", visual=True)\n",
    "query_loader = DataLoader(query_dataset, batch_size=args.batch_size, shuffle=True, num_workers=2, drop_last=False)\n",
    "\n",
    "train_dataset = Dataset(args.data, args.train_list, mode=\"test\", visual=True)\n",
    "train_loader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True, num_workers=2, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37b43296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for images, labels, im_pth, coord in train_loader:\n",
    "#     plt.figure(figsize=(8 * 4, 2 * 4))\n",
    "#     for i in range(8):\n",
    "#         im = Image.open(im_pth[i])\n",
    "#         plt.subplot(2, 8, i+1)\n",
    "#         plt.imshow(im)\n",
    "#         plt.subplot(2, 8, i+1+8)\n",
    "#         plt.imshow(images[i].permute(1, 2, 0).numpy())\n",
    "#     plt.show()\n",
    "#     plt.close()\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59bcc855",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# extract feature\n",
    "with torch.no_grad():\n",
    "    feat_dic = {}\n",
    "    for images, labels, im_pth, coord in train_loader:\n",
    "        images = images.cuda()\n",
    "        labels = labels.cuda()\n",
    "        features, _ = model(images, labels, args)\n",
    "        features = features / torch.norm(features, dim=-1, keepdim=True)\n",
    "        features = features.detach().cpu()\n",
    "        for i in range(images.shape[0]):\n",
    "            feat_dic[im_pth[i]] = {\n",
    "                \"feat\": features[i],\n",
    "                \"label\": labels[i],\n",
    "                \"coord\": coord[i]\n",
    "            }\n",
    "            \n",
    "with torch.no_grad():\n",
    "    q_feat_dic = {}\n",
    "    for images, labels, im_pth, coord in query_loader:\n",
    "        images = images.cuda()\n",
    "        labels = labels.cuda()\n",
    "        features, _ = model(images, labels, args)\n",
    "        features = features / torch.norm(features, dim=-1, keepdim=True)\n",
    "        features = features.detach().cpu()\n",
    "        for i in range(images.shape[0]):\n",
    "            q_feat_dic[im_pth[i]] = {\n",
    "                \"feat\": features[i],\n",
    "                \"label\": labels[i],\n",
    "                \"coord\": coord[i]\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e64149e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([905, 3950])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "features = []\n",
    "labels = []\n",
    "im_pth_list = []\n",
    "for im_pth in feat_dic.keys():\n",
    "    features.append(feat_dic[im_pth][\"feat\"])\n",
    "    labels.append(feat_dic[im_pth][\"label\"])\n",
    "    im_pth_list.append(im_pth)\n",
    "features = torch.stack(features)\n",
    "labels = torch.stack(labels)\n",
    "\n",
    "q_features = []\n",
    "q_labels = []\n",
    "q_im_pth_list = []\n",
    "for im_pth in q_feat_dic.keys():\n",
    "    if q_feat_dic[im_pth][\"label\"] != -1:\n",
    "        q_features.append(q_feat_dic[im_pth][\"feat\"])\n",
    "        q_labels.append(q_feat_dic[im_pth][\"label\"])\n",
    "        q_im_pth_list.append(im_pth)\n",
    "q_features = torch.stack(q_features)\n",
    "q_labels = torch.stack(q_labels)\n",
    "\n",
    "sim = torch.matmul(q_features, features.T) \n",
    "vec_ranks = torch.argsort(-sim, dim=1)\n",
    "\n",
    "print(sim.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f3cca0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1067, 10])\n",
      "N: 1.1152764761012184\n"
     ]
    }
   ],
   "source": [
    "# save top 10 label\n",
    "import pickle\n",
    "\n",
    "_, b = sim.topk(10)\n",
    "top10_labels = torch.gather(labels.cpu().expand_as(sim), dim=1, index=b)\n",
    "print(top10_labels.shape)\n",
    "query_dic = {}\n",
    "certify_cnt = 0\n",
    "for i, im_pth in enumerate(q_im_pth_list):\n",
    "    query_dic[im_pth] = {\n",
    "        \"label\": q_feat_dic[im_pth][\"label\"].cpu().numpy(),\n",
    "        \"coord\": q_feat_dic[im_pth][\"coord\"].numpy(),\n",
    "        \"top10\": top10_labels[i]\n",
    "    }\n",
    "    certify_cnt += torch.unique(top10_labels[i]).shape[0]\n",
    "print(\"N:\", certify_cnt / len(q_im_pth_list))\n",
    "with open(\"query_dic.pk\", \"wb\") as f:\n",
    "    pickle.dump(query_dic, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b915ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision@1 : 0.9945\n",
      "precision@5 : 0.9938\n",
      "precision@10 : 0.9904\n",
      "precision@20 : 0.8951\n"
     ]
    }
   ],
   "source": [
    "topk = [1, 5, 10, 20]\n",
    "for k in topk:\n",
    "    _, b =sim.topk(k)\n",
    "    target = torch.gather(labels.cpu().expand_as(sim), dim=1, index=b)\n",
    "    acc = torch.mean((target == q_labels.cpu().reshape(-1, 1).expand_as(target)).sum(dim=-1).float() / k)\n",
    "    print(\"precision@{} : {:.4f}\".format(k, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "304198a1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topk acc@1 : 0.9945\n",
      "topk acc@5 : 0.9967\n",
      "topk acc@10 : 0.9967\n",
      "topk acc@20 : 0.9989\n"
     ]
    }
   ],
   "source": [
    "topk = [1, 5, 10, 20]\n",
    "for k in topk:\n",
    "    _, b =sim.topk(k)\n",
    "    target = torch.gather(labels.cpu().expand_as(sim), dim=1, index=b)\n",
    "    acc = torch.mean(((target == q_labels.cpu().reshape(-1, 1).expand_as(target)).sum(dim=-1) > 0).float())\n",
    "    print(\"topk acc@{} : {:.4f}\".format(k, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466551af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from PIL import Image\n",
    "\n",
    "def calculate_overlap(dic1, dic2):\n",
    "    if dic1[\"label\"] != dic2[\"label\"] or dic1[\"label\"] == -1 or dic2[\"label\"] == -1:\n",
    "        overlap_area = 0\n",
    "    else:\n",
    "        x1, y1, x2, y2 = dic1[\"coord\"]\n",
    "        x3, y3, x4, y4 = dic2[\"coord\"]\n",
    "        x_overlap = max(0, min(x2, x4) - max(x1, x3))\n",
    "        y_overlap = max(0, min(y2, y4) - max(y1, y3))\n",
    "        overlap_area = x_overlap * y_overlap\n",
    "        overlap_area = float(overlap_area) / ((x2 - x1) * (y2 - y1))\n",
    "    return overlap_area\n",
    "        \n",
    "for i in range(10):\n",
    "    idx = random.randint(0, q_features.shape[0]-1)\n",
    "    plt.figure(figsize=(40, 4))\n",
    "    plt.subplot(1, 10, 1)\n",
    "    im_pth = q_im_pth_list[idx]\n",
    "    q_dic = q_feat_dic[im_pth]\n",
    "    im = Image.open(im_pth)\n",
    "    plt.imshow(im)\n",
    "    plt.title(\"Label:{}\".format(q_dic[\"label\"].item()))\n",
    "    for j in range(9):\n",
    "        plt.subplot(1, 10, j + 2)\n",
    "        im_pth = im_pth_list[vec_ranks[idx][j]]\n",
    "        im = Image.open(im_pth)\n",
    "        dic = feat_dic[im_pth]\n",
    "        overlap = calculate_overlap(q_dic, dic)\n",
    "        plt.imshow(im)\n",
    "        plt.title(\"Label:{}, Sim:{:.4f}, Overlap:{:.2f}\".format(\n",
    "            dic[\"label\"].item(), sim[idx][vec_ranks[idx][j]].item(), overlap\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ba9e61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
